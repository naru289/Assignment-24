{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/naru289/Assignment-24/blob/main/M3_AST_24_GAN_MNIST_C%20Copy.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nsOxISbFCzlj"
      },
      "source": [
        "# Advanced Programme in Deep Learning (Foundations and Applications)\n",
        "## A Program by IISc and TalentSprint\n",
        "### Assignment 24 : Implementation of Generative Adversarial Networks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0pGc7xQ2dSRL"
      },
      "source": [
        "## Learning Objectives:\n",
        "\n",
        "At the end of the experiment, you will be able to :\n",
        "\n",
        "* Understand GAN\n",
        "* Generate fake images of MNIST dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9NuRcSZydkL_"
      },
      "source": [
        "## Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5KqbKyGSdnuq"
      },
      "source": [
        "###Description\n",
        "\n",
        "We use the MNIST dataset for this experiment. Below are the details:\n",
        "\n",
        "1. The dataset contains 60,000 Handwritten digits as training samples and 10,000 Test samples,\n",
        "which means each digit occurs 6000 times in the training set and 1000 times in the testing set. (approximately).\n",
        "2. Each image is Size Normalized and Centered\n",
        "3. Each image is 28 X 28 Pixel with 0-255 Gray Scale Value.\n",
        "4. That means each image is represented as 784 (28 X28) dimension vector where each value is in the range 0- 255.\n",
        "\n",
        "### History\n",
        "\n",
        "Yann LeCun (Director of AI Research, Facebook, Courant Institute, NYU) was given the task of identifying the cheque numbers (in the 90’s) and the amount associated with that cheque without manual intervention. That is when this dataset was created which raised the bars and became a benchmark.\n",
        "\n",
        "Yann LeCun and Corinna Cortes (Google Labs, New York) hold the copyright of MNIST dataset, which is a subset of the original NIST datasets. This dataset is made available under the terms of the Creative Commons Attribution-Share Alike 3.0 license.\n",
        "\n",
        "It is the handwritten digits dataset in which half of them are written by the Census Bureau employees and remaining by the high school students. The digits collected among the Census Bureau employees are easier and cleaner to recognize than the digits collected among the students.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MJu4cGUCdwTr"
      },
      "source": [
        "## Domain Information"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vMtA8wDddypU"
      },
      "source": [
        "\n",
        "Handwriting changes person to person. Some of us have neat handwriting and some have illegible handwriting such as doctors. However, if you think about it even a child who recognizes alphabets and numerics can identify the characters of a text even written by a stranger. But even a technically knowledgeable adult cannot describe the process by which he or she recognizes the text/letters. As you know this is an excellent challenge for Machine Learning.\n",
        "\n",
        "![altxt](https://i.pinimg.com/originals/f2/7a/ac/f27aac4542c0090872110836d65f4c99.jpg)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X4F3RvUAd4Hw"
      },
      "source": [
        "## Information"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Generative Models\n",
        "\n",
        "Informally:\n",
        "\n",
        "* Generative models can generate new data instances.\n",
        "* Discriminative models discriminate between different kinds of data instances.\n",
        "\n",
        "A generative model could generate new photos of animals that look like real animals, while a discriminative model could tell a dog from a cat. GANs are just one kind of generative model.\n",
        "\n",
        "More formally, given a set of data instances X and a set of labels Y:\n",
        "\n",
        "* Generative models capture the joint probability p(X, Y), or just p(X) if there are no labels.\n",
        "* Discriminative models capture the conditional probability p(Y | X).\n",
        "\n",
        "A generative model includes the distribution of the data itself, and tells you how likely a given example is. For example, models that predict the next word in a sequence are typically generative models (usually much simpler than GANs) because they can assign a probability to a sequence of words.\n",
        "\n",
        "A discriminative model ignores the question of whether a given instance is likely, and just tells you how likely a label is to apply to the instance.\n",
        "\n",
        "Note that this is a very general definition. There are many kinds of generative model. GANs are just one kind of generative model.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "D9jcXbokfwx9"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L1qJVLV4f2tw"
      },
      "source": [
        "### Generative Adversarial Networks\n",
        "\n",
        "\n",
        "GANs are generative models devised by Goodfellow et al. in 2014. GAN is about creating, like drawing a portrait or composing a symphony. This is hard compared to other deep learning fields. For instance, it is much easier to identify a Monet painting than painting one.\n",
        "\n",
        "\n",
        "The main focus of GAN is to generate data from scratch, mostly images but other domains including music have been done.\n",
        "\n",
        "A GAN, or Generative Adversarial Network, is a generative model that simultaneously trains two models: a generative model 'G' that captures the data distribution, and a discriminative model 'D' that estimates the probability that a sample came from the training data rather than 'G'.\n",
        "\n",
        "GAN composes of two deep networks :\n",
        "\n",
        "* Generator\n",
        "* Discriminator\n",
        "\n",
        "\n",
        "#### Generator\n",
        "\n",
        "The generator tries to produce data that come from some probability distribution. The generator learns to generate plausible data. The generated instances become negative training examples for the discriminator.\n",
        "\n",
        "For example, that would be you trying to reproduce the party’s tickets.\n",
        "\n",
        "#### Discriminator\n",
        "\n",
        "The discriminator acts like a judge. It gets to decide if the input comes from the generator or from the true training set. For example, that would be the party’s security comparing your fake ticket with the true ticket to find flaws in your design.\n",
        "\n",
        "The discriminator learns to distinguish the generator's fake data from real data. The discriminator penalizes the generator for producing implausible results.\n",
        "\n",
        "When training begins, the generator produces obviously fake data, and the discriminator quickly learns to tell that it's fake.\n",
        "\n",
        "In summary, we can say that :\n",
        "\n",
        "* The generator trying to maximize the probability of making the discriminator mistake its inputs as real.\n",
        "\n",
        "* And the discriminator guiding the generator to produce more realistic images.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IfpAgIPxr1Em"
      },
      "source": [
        "![alt text](https://cdn.talentsprint.com/aiml/Experiment_related_data/IMAGES/gan.png)\n",
        "\n",
        "To illustrate this notion of “generative models”, we can take a look at some well known example on MNIST obtained with GANs"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "During training, the generator progressively becomes better and better and tries to \"fool\" the discriminator into believing the generated images are real! When the discriminator starts classifying the generated images as real, it means the generated images are of sufficient quality. The generator thus has become capable enough to \"generate images\". An example is provided below. An example is provided below:"
      ],
      "metadata": {
        "id": "vqW7EYWigMVu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://tensorflow.org/images/gan/dcgan.gif\" />"
      ],
      "metadata": {
        "id": "4KoX7P-UgGvm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Both the generator and the discriminator are neural networks. The generator output is connected directly to the discriminator input. Through backpropagation, the discriminator's classification provides a signal that the generator uses to update its weights."
      ],
      "metadata": {
        "id": "1FuOyPdaGgg2"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7OiFi8nj77AW"
      },
      "source": [
        "### Setup Steps:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xWMVQWk58aXm"
      },
      "source": [
        "#@title Please enter your registration id to start: { run: \"auto\", display-mode: \"form\" }\n",
        "Id = \"2237180\" #@param {type:\"string\"}"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cwqosl928dBA"
      },
      "source": [
        "#@title Please enter your password (normally your phone number) to continue: { run: \"auto\", display-mode: \"form\" }\n",
        "password = \"6366871391\" #@param {type:\"string\"}"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "9l1Iq4QQhk9J",
        "outputId": "3ba17327-b3a0-40c5-b1c4-3d1e4fdccb9b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "#@title Run this cell to complete the setup for this Notebook\n",
        "from IPython import get_ipython\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "ipython = get_ipython()\n",
        "\n",
        "notebook= \"M3_AST_24_GAN_MNIST_C\" #name of the notebook\n",
        "\n",
        "def setup():\n",
        "    from IPython.display import HTML, display\n",
        "    display(HTML('<script src=\"https://dashboard.talentsprint.com/aiml/record_ip.html?traineeId={0}&recordId={1}\"></script>'.format(getId(),submission_id)))\n",
        "    print(\"Setup completed successfully\")\n",
        "    return\n",
        "\n",
        "def submit_notebook():\n",
        "    ipython.magic(\"notebook -e \"+ notebook + \".ipynb\")\n",
        "\n",
        "    import requests, json, base64, datetime\n",
        "\n",
        "    url = \"https://dashboard.talentsprint.com/xp/app/save_notebook_attempts\"\n",
        "    if not submission_id:\n",
        "      data = {\"id\" : getId(), \"notebook\" : notebook, \"mobile\" : getPassword()}\n",
        "      r = requests.post(url, data = data)\n",
        "      r = json.loads(r.text)\n",
        "\n",
        "      if r[\"status\"] == \"Success\":\n",
        "          return r[\"record_id\"]\n",
        "      elif \"err\" in r:\n",
        "        print(r[\"err\"])\n",
        "        return None\n",
        "      else:\n",
        "        print (\"Something is wrong, the notebook will not be submitted for grading\")\n",
        "        return None\n",
        "\n",
        "    elif getAnswer1() and getAnswer2() and getComplexity() and getAdditional() and getConcepts() and getComments() and getMentorSupport():\n",
        "      f = open(notebook + \".ipynb\", \"rb\")\n",
        "      file_hash = base64.b64encode(f.read())\n",
        "\n",
        "      data = {\"complexity\" : Complexity, \"additional\" :Additional,\n",
        "              \"concepts\" : Concepts, \"record_id\" : submission_id,\n",
        "              \"answer1\" : Answer1, \"answer2\" : Answer2, \"id\" : Id, \"file_hash\" : file_hash,\n",
        "              \"notebook\" : notebook,\n",
        "              \"feedback_experiments_input\" : Comments,\n",
        "              \"feedback_mentor_support\": Mentor_support}\n",
        "      r = requests.post(url, data = data)\n",
        "      r = json.loads(r.text)\n",
        "      if \"err\" in r:\n",
        "        print(r[\"err\"])\n",
        "        return None\n",
        "      else:\n",
        "        print(\"Your submission is successful.\")\n",
        "        print(\"Ref Id:\", submission_id)\n",
        "        print(\"Date of submission: \", r[\"date\"])\n",
        "        print(\"Time of submission: \", r[\"time\"])\n",
        "        print(\"View your submissions: https://dlfa-iisc.talentsprint.com/notebook_submissions\")\n",
        "        #print(\"For any queries/discrepancies, please connect with mentors through the chat icon in LMS dashboard.\")\n",
        "        return submission_id\n",
        "    else: submission_id\n",
        "\n",
        "\n",
        "def getAdditional():\n",
        "  try:\n",
        "    if not Additional:\n",
        "      raise NameError\n",
        "    else:\n",
        "      return Additional\n",
        "  except NameError:\n",
        "    print (\"Please answer Additional Question\")\n",
        "    return None\n",
        "\n",
        "def getComplexity():\n",
        "  try:\n",
        "    if not Complexity:\n",
        "      raise NameError\n",
        "    else:\n",
        "      return Complexity\n",
        "  except NameError:\n",
        "    print (\"Please answer Complexity Question\")\n",
        "    return None\n",
        "\n",
        "def getConcepts():\n",
        "  try:\n",
        "    if not Concepts:\n",
        "      raise NameError\n",
        "    else:\n",
        "      return Concepts\n",
        "  except NameError:\n",
        "    print (\"Please answer Concepts Question\")\n",
        "    return None\n",
        "\n",
        "\n",
        "# def getWalkthrough():\n",
        "#   try:\n",
        "#     if not Walkthrough:\n",
        "#       raise NameError\n",
        "#     else:\n",
        "#       return Walkthrough\n",
        "#   except NameError:\n",
        "#     print (\"Please answer Walkthrough Question\")\n",
        "#     return None\n",
        "\n",
        "def getComments():\n",
        "  try:\n",
        "    if not Comments:\n",
        "      raise NameError\n",
        "    else:\n",
        "      return Comments\n",
        "  except NameError:\n",
        "    print (\"Please answer Comments Question\")\n",
        "    return None\n",
        "\n",
        "\n",
        "def getMentorSupport():\n",
        "  try:\n",
        "    if not Mentor_support:\n",
        "      raise NameError\n",
        "    else:\n",
        "      return Mentor_support\n",
        "  except NameError:\n",
        "    print (\"Please answer Mentor support Question\")\n",
        "    return None\n",
        "\n",
        "def getAnswer1():\n",
        "  try:\n",
        "    if not Answer1:\n",
        "      raise NameError\n",
        "    else:\n",
        "      return Answer1\n",
        "  except NameError:\n",
        "    print (\"Please answer Question 1\")\n",
        "    return None\n",
        "\n",
        "def getAnswer2():\n",
        "  try:\n",
        "    if not Answer2:\n",
        "      raise NameError\n",
        "    else:\n",
        "      return Answer2\n",
        "  except NameError:\n",
        "    print (\"Please answer Question 2\")\n",
        "    return None\n",
        "\n",
        "\n",
        "def getId():\n",
        "  try:\n",
        "    return Id if Id else None\n",
        "  except NameError:\n",
        "    return None\n",
        "\n",
        "def getPassword():\n",
        "  try:\n",
        "    return password if password else None\n",
        "  except NameError:\n",
        "    return None\n",
        "\n",
        "submission_id = None\n",
        "### Setup\n",
        "if getPassword() and getId():\n",
        "  submission_id = submit_notebook()\n",
        "  if submission_id:\n",
        "    setup()\n",
        "else:\n",
        "  print (\"Please complete Id and Password cells before running setup\")\n",
        "\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<script src=\"https://dashboard.talentsprint.com/aiml/record_ip.html?traineeId=2237180&recordId=2049\"></script>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setup completed successfully\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eBD0M7uyinT3"
      },
      "source": [
        "### Importing required  Packages\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N0WQEuRFNF8A"
      },
      "source": [
        "import itertools\n",
        "import math\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython import display\n",
        "\n",
        "# Pytorch Packages\n",
        "import torch\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "import torchvision.datasets as dsets\n",
        "import torchvision.transforms as transforms"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EUarXxbEC246"
      },
      "source": [
        "### Loading the MNIST data\n",
        "\n",
        "Now, we'll load the MNIST data. For the first time, we may have to download the data, which can take a while.\n",
        "\n",
        "Now,\n",
        "\n",
        "* We will load both the training set and the testing sets\n",
        "\n",
        "* We will use transform.compose(), which combines all the transformation that are provided to be applied on the dataset.\n",
        "\n",
        "* We will use transforms.ToTensor() which converts the input images to PyTorch tensor.  \n",
        "\n",
        "* We also use transforms.Normalize() which is to scale the input images and the precomputed values (mean and std) for the dataset is passed to the Normalize() method.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4lk_QTO1NLqg"
      },
      "source": [
        "transform = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.5,), (0.5,))])\n",
        "\n",
        "train_dataset = dsets.MNIST(root='./data/', train=True, download=True, transform=transform)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bmxkoOr_v6oh"
      },
      "source": [
        " Let’s visualize a image from the training set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ywedmu7Rv0dJ"
      },
      "source": [
        "# Plotting one example\n",
        "print(\"Shape of the training data (no of images, height, width) : \", train_dataset.train_data.size()) # (60000, 28, 28)\n",
        "print(\"\\n\")\n",
        "print(\"An Example Image\")\n",
        "plt.imshow(train_dataset.train_data[0].numpy(), cmap='gray')\n",
        "plt.title('Label : %i' % train_dataset.train_labels[0])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "asuxbx_aBsp5"
      },
      "source": [
        "**torch.utils.data.DataLoader** class represents a Python iterable over a dataset, with following features.\n",
        "\n",
        "1. Batching the data - `batch_size`, which denotes the number of samples (images) contained in each generated batch. The Machine learning dataset can be really large. Hence we cannot often load the entire data into the memory. Hence neural network training is done by loading small batches (commonly called minibatch) of data and using it to update the learnable parameters (weights and biases) of the model.\n",
        "\n",
        "2. Shuffling the data - If set to `shuffle=True`, we will get a new order of exploration at each pass. Shuffling the order in which examples are fed to the classifier is helpful so that batches between epochs do not look alike. By performing it will eventually make our model more robust.\n",
        "\n",
        "\n",
        "\n",
        "The train data is provided via data loaders that provide iterators over the datasets to train our models."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# The mini batch size used for training\n",
        "batch_size = 100\n",
        "\n",
        "# Loading the train dataset\n",
        "# Data Loader loads the images and corresponding labels of defined mini batch size.\n",
        "# the image batch shape will be (batch_size, 1, 28, 28)\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)"
      ],
      "metadata": {
        "id": "Esq4K0GtIs9S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The train and test data are provided via data loaders that provide iterators over the datasets.\n",
        "\n",
        "The first element of training data (X_train) is a 4th-order tensor of size (batch_size, 1, 28, 28), i.e. it consists of a batch of images of size 1x28x28 pixels where '1' represents one input image channel i.e. grey scale. y_train is a vector containing the correct classes (\"0\", \"1\", ..., \"9\") for each training digit."
      ],
      "metadata": {
        "id": "HeW92Jf8KxPL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for (X_train, y_train) in train_loader:\n",
        "    print('X_train:', X_train.size(), 'type:', X_train.type())\n",
        "    print('y_train:', y_train.size(), 'type:', y_train.type())\n",
        "    break"
      ],
      "metadata": {
        "id": "k58fyk7yKyRL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Plotting the  first 10 training digit images"
      ],
      "metadata": {
        "id": "xVhOyUr6KmN5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pltsize=2\n",
        "plt.figure(figsize=(15*pltsize, pltsize))\n",
        "\n",
        "for i in range(10):\n",
        "    plt.subplot(1,10,i+1)\n",
        "    plt.axis('off')\n",
        "\n",
        "    plt.imshow(X_train[i,:,:,:].numpy().reshape(28,28), cmap=\"gray\")\n",
        "    plt.title('Class: '+str(y_train[i]))"
      ],
      "metadata": {
        "id": "kz7BUDiTKhj4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DSTlJWI8NVX7"
      },
      "source": [
        "### Defining the Discriminator Model"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The discriminator is a binary classifier consisting of only **fully-connected layers**.\n",
        "\n",
        "* Inputs the flattened image of dimension 784, and outputs a score between 0 and 1.\n",
        "    \n",
        "* Has Leaky Relu in the intermediate layers\n",
        "    \n",
        "* Has the Sigmoid activation function in the output layer\n",
        "\n",
        "The forward function of the discriminator, flattens the input feeds from the vector to the discriminator, and returns the result, indicating whether the image is real or fake."
      ],
      "metadata": {
        "id": "q0lTNs0GF95H"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G6WC2JuiNShJ"
      },
      "source": [
        "class Discriminator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Linear(784, 1024),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(1024, 512),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(512, 256),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(256, 1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.model(x.view(x.size(0), 784))\n",
        "        out = out.view(out.size(0), -1)\n",
        "        return out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JkyQx9eGNWPQ"
      },
      "source": [
        "### Defining the Generator Model"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Generator is a **fully connected network** that takes a noise vector (latent_dim) as an input and outputs a `784-dimensional vector`. Consider the generator as a decoder fed with a low-dimensional vector (100-d) and outputs an upsampled high-dimensional vector (784-d).\n",
        "\n",
        "\n",
        "The network mainly consists of dense layers, leakyrelu & tanh activation function.\n",
        "\n",
        "* The first layer has `256` neurons, doubled at every new linear layer, up to `1024` neurons.\n",
        "    \n",
        "* `Leaky ReLU` has been used as the activation function in this network for the intermediate layers with a negative slope as 0.2, meaning the features with a value below -0.2 will be squashed to 0.\n",
        "\n",
        "* The last linear layer has input neurons as `1024` and the output dimension as `784(28*28)` neurons\n",
        "    \n",
        "* The `tanh` activation at the output layer ensures that the pixel values are mapped in line with its own output, i.e., between (-1, 1) ( remember, we normalized the images to range [-1, 1] ).\n"
      ],
      "metadata": {
        "id": "6BT2rH7mDm3t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The forward the function of the generator feeds the noise vector (normal distribution) to the model, then reshapes the 784-d vector to (1, 28, 28), the original image shape, and finally, the image is returned. The generator, as we know, mimics the real data distribution without actually seeing it."
      ],
      "metadata": {
        "id": "TFvqFB32FyE9"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MtiXrEclNW1p"
      },
      "source": [
        "class Generator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Linear(100, 256),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Linear(256, 512),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Linear(512, 1024),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Linear(1024, 784),\n",
        "            nn.Tanh()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(x.size(0), 100)\n",
        "        out = self.model(x)\n",
        "        return out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HUPeKiV1uTnZ"
      },
      "source": [
        "### Initializing the CUDA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eji1M8AFN5wW"
      },
      "source": [
        "use_cuda = torch.cuda.is_available()\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Creating the Generator and Discriminator instance"
      ],
      "metadata": {
        "id": "R1hJUQVwHB9_"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mOCjnR7pNZwG"
      },
      "source": [
        "discriminator = Discriminator().to(device)\n",
        "generator = Generator().to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zWV3XqY5OMVQ"
      },
      "source": [
        "### Defining the Optimizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_kBbD1H9OJVx"
      },
      "source": [
        "criterion = nn.BCELoss()\n",
        "lr = 0.0002\n",
        "d_optimizer = torch.optim.Adam(discriminator.parameters(), lr=lr)\n",
        "g_optimizer = torch.optim.Adam(generator.parameters(), lr=lr)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V8kVlovDORTG"
      },
      "source": [
        "### Training Discriminator Function\n",
        "\n",
        "1. Input, the Discriminator, takes the real data from the training dataset and the fake data from the generator.\n",
        "\n",
        "#### Discriminator loss\n",
        "\n",
        "The discriminator's loss quantifies how well the discriminator is able to distinguish real images from fakes. It compares the discriminator's predictions on real images to an array of 1s, and the discriminator's predictions on fake (generated) images to an array of 0s."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cerV5nOKOOoz"
      },
      "source": [
        "def train_discriminator(discriminator, images, real_labels, fake_images, fake_labels):\n",
        "\n",
        "    # Train on real images\n",
        "    # Reset gradients\n",
        "    discriminator.zero_grad()\n",
        "    prediction_real = discriminator(images)\n",
        "\n",
        "    # Comparing original images\n",
        "    real_loss = criterion(prediction_real, real_labels)\n",
        "\n",
        "    # Train on fake images\n",
        "    prediction_fake = discriminator(fake_images)\n",
        "\n",
        "    # Comparing fake images\n",
        "    # Calculate error and backpropagate\n",
        "    fake_loss = criterion(prediction_fake, fake_labels)\n",
        "    d_loss = real_loss + fake_loss\n",
        "    d_loss.backward()\n",
        "\n",
        "    # Update weights with gradients\n",
        "    d_optimizer.step()\n",
        "    return d_loss, prediction_real, prediction_fake"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ucVw5ikMxFZx"
      },
      "source": [
        "### Training Generator Function\n",
        "\n",
        "#### Generator loss\n",
        "\n",
        "The generator's loss quantifies how well it was able to trick the discriminator. Intuitively, if the generator is performing well, the discriminator will classify the fake images as real (or 1). Here, compare the discriminators decisions on the generated images to an array of 1s."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C0lpHk9QOZ52"
      },
      "source": [
        "def train_generator(generator, fake_images, real_labels):\n",
        "    # Train Generator\n",
        "    # Reset gradients\n",
        "    generator.zero_grad()\n",
        "\n",
        "    # Sample noise and generate fake data\n",
        "    discriminator_outputs = discriminator(fake_images)\n",
        "\n",
        "    # Calculate error and backpropagate\n",
        "    g_loss = criterion(discriminator_outputs, real_labels)\n",
        "    g_loss.backward()\n",
        "\n",
        "    # Update weights with gradients\n",
        "    g_optimizer.step()\n",
        "\n",
        "    # Return error\n",
        "    return g_loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NoSFz9yu_hwx"
      },
      "source": [
        "### Generate Samples for Testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uf9-TwixOihO"
      },
      "source": [
        "# Draw samples from the input distribution to inspect the generation on training\n",
        "num_test_samples = 16\n",
        "test_noise = torch.randn(num_test_samples, 100).to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b3929IPDf_MD"
      },
      "source": [
        "### Lets start training the GAN, in below output the image gets updated for every iteration\n",
        "\n",
        "**Note:** The below training process for 150 epochs will take around 1hr 15 mins to complete the execution."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir results"
      ],
      "metadata": {
        "id": "YP8n-7hK0Q2M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aqdz84moOnxw"
      },
      "source": [
        "# Create figure for plotting\n",
        "size_figure_grid = int(math.sqrt(num_test_samples))\n",
        "fig, ax = plt.subplots(size_figure_grid, size_figure_grid, figsize=(6, 6))\n",
        "for i, j in itertools.product(range(size_figure_grid), range(size_figure_grid)):\n",
        "    ax[i,j].get_xaxis().set_visible(False)\n",
        "    ax[i,j].get_yaxis().set_visible(False)\n",
        "\n",
        "# Set number of epochs and initialize figure counter\n",
        "num_epochs = 100    # Increase the no of epochs to see the better quality images\n",
        "num_batches = len(train_loader)\n",
        "num_fig = 0\n",
        "\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    for n, (images, _) in enumerate(train_loader):\n",
        "        images = images.to(device)\n",
        "        real_labels = torch.ones(images.size(0), 1).to(device)\n",
        "\n",
        "        # Sample from generator\n",
        "        # Generate fake images by passing the random noise vector to the generator\n",
        "        noise = torch.randn(images.size(0), 100).to(device)\n",
        "        fake_images = generator(noise)\n",
        "        fake_labels = torch.zeros(images.size(0), 1).to(device)\n",
        "\n",
        "        # Train the discriminator\n",
        "        d_loss, d_pred_real, d_pred_fake = train_discriminator(discriminator, images, real_labels, fake_images, fake_labels)\n",
        "\n",
        "        # Sample again from the generator\n",
        "        noise = torch.randn(images.size(0), 100).to(device)\n",
        "        fake_images = generator(noise)\n",
        "\n",
        "        # Train the generator\n",
        "        g_loss = train_generator(generator, fake_images, real_labels)\n",
        "\n",
        "        if (n+1) % 100 == 0:\n",
        "            test_images = generator(test_noise)\n",
        "\n",
        "            for k in range(num_test_samples):\n",
        "                i = k//4\n",
        "                j = k%4\n",
        "                ax[i,j].cla()\n",
        "                ax[i,j].imshow(test_images[k,:].data.cpu().numpy().reshape(28, 28), cmap='Greys')\n",
        "            display.clear_output(wait=True)\n",
        "            display.display(plt.gcf())\n",
        "\n",
        "            plt.savefig('results/mnist-gan-%03d.png')\n",
        "            num_fig += 1\n",
        "            print('Epoch [%d/%d], Step[%d/%d], d_loss: %.4f, g_loss: %.4f, '\n",
        "                  'D(x): %.2f, D(G(z)): %.2f'\n",
        "                  %(epoch + 1, num_epochs, n+1, num_batches, d_loss.item(), g_loss.item(),\n",
        "                    d_pred_real.data.mean(), d_pred_fake.data.mean()))\n",
        "\n",
        "fig.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VHfHdGCP_n6Y"
      },
      "source": [
        "### Please answer the questions below to complete the experiment:\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Consider the following statements about GANs and answer question Q.1\n",
        "\n",
        "\n",
        "A. The generator takes as input a random noise and transforms it into an imitation of the real image and attempts to fool the discriminator.\n",
        "\n",
        "B. The discriminator takes as input a random noise and transforms it into an imitation of the real image and attempts to fool the generator.\n",
        "\n",
        "C. The discriminator distinguishes between the real image and the image\n",
        "created by the generator.\n",
        "\n",
        "D. The generator distinguishes between the real image and the image created by the discriminator."
      ],
      "metadata": {
        "id": "jYgyX2trhXrY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "cellView": "form",
        "id": "-INhmnH1RDq0"
      },
      "outputs": [],
      "source": [
        "#@title Q.1. Which of the above statement(s) is/are True regarding Generator and Discriminator in GANs?\n",
        "Answer1 = \"Both A and C\" #@param [\"\",\"Only A\",\"Only C\", \"Only D\", \"Both A and B\", \"Both A and C\", \"Both C and D\"]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Consider the below cost function and study the following statements and answer question Q.2\n",
        "\n",
        "<br>\n",
        "\n",
        "$E_x[log(D(x))] + E_z[log(1 - D(G(z)))]$\n",
        "\n",
        "<br>\n",
        "\n",
        "A. The generator loss is then calculated from the discriminator's classification - it gets rewarded if it successfully fools the discriminator, and gets penalized otherwise.\n",
        "\n",
        "B. The generator can't directly affect the $log(D(x))$ term in the function, so, for the generator, minimizing the loss is equivalent to minimizing $log(1 - D(G(z)))$.\n",
        "\n"
      ],
      "metadata": {
        "id": "2G0LtKWBXY-9"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "_F3RfGojqZDc"
      },
      "source": [
        "#@title Q.2. Which of the above statement(s) is/are True?\n",
        "Answer2 = \"Both A and B\" #@param [\"\",\"Only A\", \"Only B\", \"Both A and B\", \"Neither A nor B\"]\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NMzKSbLIgFzQ"
      },
      "source": [
        "#@title How was the experiment? { run: \"auto\", form-width: \"500px\", display-mode: \"form\" }\n",
        "Complexity = \"Good and Challenging for me\" #@param [\"\",\"Too Simple, I am wasting time\", \"Good, But Not Challenging for me\", \"Good and Challenging for me\", \"Was Tough, but I did it\", \"Too Difficult for me\"]\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DjcH1VWSFI2l"
      },
      "source": [
        "#@title If it was too easy, what more would you have liked to be added? If it was very difficult, what would you have liked to have been removed? { run: \"auto\", display-mode: \"form\" }\n",
        "Additional = \"NA\" #@param {type:\"string\"}\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4VBk_4VTAxCM"
      },
      "source": [
        "#@title Can you identify the concepts from the lecture which this experiment covered? { run: \"auto\", vertical-output: true, display-mode: \"form\" }\n",
        "Concepts = \"Yes\" #@param [\"\",\"Yes\", \"No\"]\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XH91cL1JWH7m"
      },
      "source": [
        "#@title  Text and image description/explanation and code comments within the experiment: { run: \"auto\", vertical-output: true, display-mode: \"form\" }\n",
        "Comments = \"Somewhat Useful\" #@param [\"\",\"Very Useful\", \"Somewhat Useful\", \"Not Useful\", \"Didn't use\"]\n"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z8xLqj7VWIKW"
      },
      "source": [
        "#@title Mentor Support: { run: \"auto\", vertical-output: true, display-mode: \"form\" }\n",
        "Mentor_support = \"Somewhat Useful\" #@param [\"\",\"Very Useful\", \"Somewhat Useful\", \"Not Useful\", \"Didn't use\"]\n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "FzAZHt1zw-Y-",
        "outputId": "07710f59-805d-4e80-b018-ca80ca49740d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#@title Run this cell to submit your notebook for grading { vertical-output: true }\n",
        "try:\n",
        "  if submission_id:\n",
        "      return_id = submit_notebook()\n",
        "      if return_id : submission_id = return_id\n",
        "  else:\n",
        "      print(\"Please complete the setup first.\")\n",
        "except NameError:\n",
        "  print (\"Please complete the setup first.\")"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Your submission is successful.\n",
            "Ref Id: 2049\n",
            "Date of submission:  02 Jul 2023\n",
            "Time of submission:  16:11:52\n",
            "View your submissions: https://dlfa-iisc.talentsprint.com/notebook_submissions\n"
          ]
        }
      ]
    }
  ]
}